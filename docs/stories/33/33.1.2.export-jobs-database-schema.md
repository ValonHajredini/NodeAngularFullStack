# Story 33.1.2: Export Jobs Database Schema

**Epic:** 33.1 Export Core Infrastructure (23 pts) **Story Points:** 5 **Priority:** Critical
**Status:** Draft **Created:** 2025-10-24

---

## Description

Design and implement the PostgreSQL database schema for the `export_jobs` table to persist export
job state, progress tracking, and audit trail. Include migration scripts (UP/DOWN), indexes for
query performance, foreign key constraints, and seed data for testing. Ensure schema supports
real-time polling, job resumption after interruptions, and historical audit queries.

---

## Acceptance Criteria

### Table Schema

- [ ] Create `export_jobs` table with 15+ columns
- [ ] `job_id` (UUID, PRIMARY KEY) - Unique export job identifier
- [ ] `tool_id` (UUID, FOREIGN KEY → tool_registry.tool_id) - Tool being exported
- [ ] `user_id` (UUID, FOREIGN KEY → users.user_id) - User who initiated export
- [ ] `status` (ENUM: pending, in_progress, completed, failed, cancelled, cancelling, rolled_back) -
      Job lifecycle state
- [ ] `steps_completed` (INTEGER, DEFAULT 0) - Number of completed steps
- [ ] `steps_total` (INTEGER, DEFAULT 0) - Total number of steps
- [ ] `current_step` (VARCHAR(255)) - Current step description
- [ ] `progress_percentage` (INTEGER, DEFAULT 0) - Calculated progress (0-100)
- [ ] `package_path` (VARCHAR(500), NULLABLE) - Path to generated export package
- [ ] `package_size_bytes` (BIGINT, NULLABLE) - Size of export package
- [ ] `error_message` (TEXT, NULLABLE) - Error details if status=failed
- [ ] `created_at` (TIMESTAMP WITH TIME ZONE, DEFAULT NOW()) - Job creation timestamp
- [ ] `updated_at` (TIMESTAMP WITH TIME ZONE, DEFAULT NOW()) - Last update timestamp
- [ ] `started_at` (TIMESTAMP WITH TIME ZONE, NULLABLE) - Job start timestamp
- [ ] `completed_at` (TIMESTAMP WITH TIME ZONE, NULLABLE) - Job completion timestamp

### Indexes

- [ ] PRIMARY KEY on `job_id`
- [ ] INDEX on `tool_id` (frequent lookups by tool)
- [ ] INDEX on `user_id` (user's export history queries)
- [ ] INDEX on `status` (query pending/in_progress jobs)
- [ ] COMPOSITE INDEX on `(user_id, created_at DESC)` (user history with sorting)
- [ ] INDEX on `created_at` (cleanup old jobs)

### Constraints

- [ ] FOREIGN KEY `tool_id` REFERENCES `tool_registry(tool_id)` ON DELETE CASCADE
- [ ] FOREIGN KEY `user_id` REFERENCES `users(user_id)` ON DELETE SET NULL
- [ ] CHECK constraint: `status` IN valid ENUM values
- [ ] CHECK constraint: `steps_completed <= steps_total`
- [ ] CHECK constraint: `progress_percentage BETWEEN 0 AND 100`
- [ ] CHECK constraint: `package_size_bytes >= 0` (if not null)
- [ ] NOT NULL constraints on required fields (job_id, tool_id, status, created_at)

### Migration Scripts

- [ ] UP migration: `027_create_export_jobs_table.sql`
- [ ] DOWN migration: `DOWN_027_drop_export_jobs_table.sql`
- [ ] Migration follows project naming conventions
- [ ] Migration is idempotent (IF NOT EXISTS checks)
- [ ] Migration includes descriptive comments

### Seed Data

- [ ] Create `apps/api/database/seeds/007_seed_export_jobs.ts`
- [ ] Seed 5 test export jobs with various statuses
- [ ] Seed data includes completed, in_progress, and failed jobs
- [ ] Seed data uses existing tool_id and user_id references
- [ ] Seed script is idempotent (check existence before insert)

### Testing

- [ ] Migration test: UP migration creates table successfully
- [ ] Migration test: DOWN migration drops table successfully
- [ ] Migration test: Idempotency (run UP twice, no errors)
- [ ] Integration test: Insert export job record
- [ ] Integration test: Query export jobs by user_id
- [ ] Integration test: Foreign key constraint enforcement (invalid tool_id fails)
- [ ] Integration test: CHECK constraints enforcement (invalid status fails)
- [ ] Performance test: Query with 10,000 export jobs (< 100ms)

---

## Tasks

### 1. Design Export Jobs Schema

**Estimated:** 2 hours **Dependencies:** Story 30.1.1 (Tool Registry Schema) **Description:** Define
table structure, columns, data types, and constraints.

**Subtasks:**

1. Document table purpose and relationships in design doc
2. Define primary key (job_id UUID)
3. Define foreign keys (tool_id, user_id)
4. Define status ENUM with 7 states (pending, in_progress, completed, failed, cancelled, cancelling,
   rolled_back)
5. Define progress tracking columns (steps_completed, steps_total, progress_percentage,
   current_step)
6. Define audit trail columns (created_at, updated_at, started_at, completed_at)
7. Define result columns (package_path, package_size_bytes, error_message)
8. Determine column nullability and default values
9. Design indexes for query performance (primary use cases: polling, user history)
10. Document schema in `docs/architecture/export-jobs-schema.md`

### 2. Create UP Migration Script

**Estimated:** 3 hours **Dependencies:** Task 1 **Description:** Write SQL migration to create
export_jobs table with all constraints.

**Subtasks:**

1. Create `apps/api/database/migrations/027_create_export_jobs_table.sql`
2. Add file header comment with description and date
3. Create status ENUM type if not exists
4. Write CREATE TABLE statement with all columns
5. Add PRIMARY KEY constraint on job_id
6. Add FOREIGN KEY constraint for tool_id with CASCADE delete
7. Add FOREIGN KEY constraint for user_id with SET NULL delete
8. Add CHECK constraint for status ENUM
9. Add CHECK constraint for steps_completed <= steps_total
10. Add CHECK constraint for progress_percentage range (0-100)

### 3. Create Indexes for Performance

**Estimated:** 1 hour **Dependencies:** Task 2 **Description:** Add database indexes optimized for
common query patterns.

**Subtasks:**

1. Create INDEX on tool_id column (query export jobs for a tool)
2. Create INDEX on user_id column (user export history)
3. Create INDEX on status column (query pending/in_progress jobs)
4. Create COMPOSITE INDEX on (user_id, created_at DESC) for sorted user history
5. Create INDEX on created_at for cleanup queries (delete old jobs)
6. Add INDEX creation to UP migration script
7. Document index rationale in migration comments
8. Test query performance with indexes using EXPLAIN ANALYZE
9. Verify indexes created successfully after migration
10. Document expected query performance improvements

### 4. Create DOWN Migration Script

**Estimated:** 1 hour **Dependencies:** Task 2 **Description:** Write rollback migration to drop
export_jobs table and cleanup.

**Subtasks:**

1. Create `apps/api/database/migrations/DOWN_027_drop_export_jobs_table.sql`
2. Add file header comment matching UP migration
3. Write DROP TABLE IF EXISTS statement for export_jobs
4. Write DROP TYPE IF EXISTS statement for status ENUM
5. Add CASCADE option to handle foreign key references
6. Test DOWN migration rolls back UP migration cleanly
7. Verify no orphaned objects after rollback
8. Document rollback procedure in migration comments
9. Add rollback to migration test suite
10. Verify idempotency of DOWN migration (run twice, no errors)

### 5. Add Migration Runner Support

**Estimated:** 2 hours **Dependencies:** Task 2, Task 4 **Description:** Integrate migration into
project migration runner.

**Subtasks:**

1. Add migration to `apps/api/database/migrations/run-migrations.ts` runner
2. Ensure migration runs in correct order (after 026_create_tool_registry_table.sql)
3. Test migration with `npm --workspace=apps/api run db:migrate` command
4. Verify migration entry added to `migrations` tracking table
5. Test rollback with custom migration runner script
6. Add migration status check to health endpoint
7. Document migration commands in README.md
8. Add error handling for failed migrations
9. Test migration on clean database (no existing tables)
10. Test migration on existing database (with tool_registry table)

### 6. Create Seed Data Script

**Estimated:** 2 hours **Dependencies:** Task 5 **Description:** Generate test data for export jobs
table.

**Subtasks:**

1. Create `apps/api/database/seeds/007_seed_export_jobs.ts`
2. Query existing tool_id from tool_registry table (use first tool)
3. Query existing user_id from users table (use admin user)
4. Seed job 1: Completed export (status=completed, 100% progress)
5. Seed job 2: In-progress export (status=in_progress, 50% progress)
6. Seed job 3: Failed export (status=failed, error_message populated)
7. Seed job 4: Pending export (status=pending, 0% progress)
8. Seed job 5: Cancelled export (status=cancelled, partial progress)
9. Add idempotency check (SELECT before INSERT)
10. Test seed script with `npm --workspace=apps/api run db:seed`

### 7. Create ExportJobRepository

**Estimated:** 3 hours **Dependencies:** Task 5 **Description:** Implement repository pattern for
export_jobs table access.

**Subtasks:**

1. Create `apps/api/src/repositories/export-job.repository.ts`
2. Implement `create(jobData)` method with INSERT query
3. Implement `findById(jobId)` method with SELECT query
4. Implement `update(jobId, updates)` method with UPDATE query
5. Implement `findByUserId(userId)` method for user export history
6. Implement `findByStatus(status)` method for job queue queries
7. Implement `delete(jobId)` method for cleanup (soft delete optional)
8. Add TypeScript interfaces for job data (CreateJobDto, UpdateJobDto)
9. Add error handling for database errors (duplicate key, foreign key violation)
10. Export repository from `apps/api/src/repositories/index.ts`

### 8. Unit Tests for ExportJobRepository

**Estimated:** 3 hours **Dependencies:** Task 7 **Description:** Comprehensive unit tests for
repository methods.

**Subtasks:**

1. Create `apps/api/tests/unit/repositories/export-job.repository.test.ts`
2. Mock database connection with jest.mock('pg')
3. Test `create()` inserts new export job
4. Test `findById()` retrieves export job by ID
5. Test `findById()` returns null for non-existent job
6. Test `update()` modifies export job fields
7. Test `findByUserId()` returns user's export jobs
8. Test `findByStatus()` returns jobs with matching status
9. Test foreign key constraint violation handling
10. Achieve ≥90% test coverage for repository

### 9. Integration Tests for Migration

**Estimated:** 2 hours **Dependencies:** Task 5 **Description:** Test migration execution and
rollback in real database.

**Subtasks:**

1. Create `apps/api/tests/integration/export-jobs-migration.test.ts`
2. Setup test database connection before tests
3. Test UP migration creates export_jobs table
4. Verify table columns exist with correct data types
5. Verify PRIMARY KEY constraint created
6. Verify FOREIGN KEY constraints created
7. Verify CHECK constraints enforce rules
8. Verify indexes created successfully
9. Test DOWN migration drops export_jobs table
10. Cleanup test database after tests

### 10. Integration Tests for Repository

**Estimated:** 3 hours **Dependencies:** Task 7, Task 9 **Description:** Test repository methods
against real PostgreSQL database.

**Subtasks:**

1. Create `apps/api/tests/integration/export-job.repository.integration.test.ts`
2. Setup test database with migration and seed data
3. Test `create()` inserts job and returns record
4. Test `findById()` retrieves inserted job
5. Test `update()` modifies job status and progress
6. Test `findByUserId()` returns only user's jobs
7. Test `findByStatus()` filters by status enum
8. Test foreign key constraint (insert with invalid tool_id fails)
9. Test CHECK constraint (insert with invalid status fails)
10. Cleanup test data after tests

### 11. Query Performance Testing

**Estimated:** 2 hours **Dependencies:** Task 3, Task 7 **Description:** Verify query performance
with large dataset.

**Subtasks:**

1. Create `apps/api/tests/performance/export-jobs-queries.test.ts`
2. Seed 10,000 export jobs into test database
3. Measure `findById()` query time (should be < 10ms)
4. Measure `findByUserId()` query time (should be < 50ms)
5. Measure `findByStatus()` query time (should be < 100ms)
6. Run EXPLAIN ANALYZE on each query
7. Verify indexes used (check query plan)
8. Identify slow queries and optimize
9. Document performance benchmarks in test file
10. Add performance test to CI/CD pipeline

### 12. Add Schema to Shared Types

**Estimated:** 1 hour **Dependencies:** Task 1 **Description:** Define TypeScript interfaces in
shared package.

**Subtasks:**

1. Create `packages/shared/src/types/export.types.ts`
2. Define `ExportJobStatus` enum matching database ENUM
3. Define `ExportJob` interface with all table columns
4. Define `CreateExportJobDto` interface for job creation
5. Define `UpdateExportJobDto` interface for job updates
6. Export interfaces from `packages/shared/src/index.ts`
7. Build shared package (`npm run build:shared`)
8. Import `ExportJob` in backend repository
9. Import `ExportJob` in frontend service (Story 32.2.4)
10. Verify type safety across frontend and backend

### 13. Add Foreign Key Cascade Logic

**Estimated:** 2 hours **Dependencies:** Task 2 **Description:** Define cascade behavior for deleted
tools or users.

**Subtasks:**

1. Set `tool_id` FOREIGN KEY to CASCADE on delete (delete jobs when tool deleted)
2. Set `user_id` FOREIGN KEY to SET NULL on delete (preserve jobs when user deleted)
3. Test tool deletion cascades to export_jobs (integration test)
4. Test user deletion sets user_id to NULL (integration test)
5. Document cascade behavior in migration comments
6. Add warning in repository when deleting tools (affects export jobs)
7. Consider soft delete alternative (deleted_at column)
8. Document cascade decisions in architecture docs
9. Add cascade behavior to QA gate checklist
10. Verify cascade behavior in production-like environment

### 14. Add Job Cleanup Cron Job

**Estimated:** 2 hours **Dependencies:** Task 7 **Description:** Implement automated cleanup of old
export jobs.

**Subtasks:**

1. Create `apps/api/src/jobs/export-cleanup.job.ts`
2. Implement cleanup logic (delete jobs older than 30 days)
3. Add configurable retention period (environment variable)
4. Delete completed jobs after retention period
5. Delete failed jobs after retention period
6. Keep in_progress jobs indefinitely (manual cleanup)
7. Delete associated export package files (filesystem cleanup)
8. Log cleanup operations with count of deleted jobs
9. Schedule cron job to run daily at 2 AM
10. Add unit tests for cleanup logic

### 15. Documentation and Examples

**Estimated:** 1 hour **Dependencies:** All previous tasks **Description:** Document schema design
and usage examples.

**Subtasks:**

1. Create `docs/architecture/export-jobs-schema.md`
2. Add ER diagram showing relationships (export_jobs ← tool_registry, users)
3. Document each table column with purpose and examples
4. Document status state machine (pending → in_progress → completed/failed)
5. Add SQL query examples (common queries)
6. Document index usage and query optimization tips
7. Add migration rollback procedure
8. Document foreign key cascade behavior
9. Add troubleshooting section (common issues)
10. Link schema docs from root README.md

---

## Dev Notes

### Database Schema Design

```sql
-- apps/api/database/migrations/027_create_export_jobs_table.sql

/**
 * Migration: Create export_jobs table
 * Purpose: Track export job lifecycle, progress, and audit trail
 * Author: Development Team
 * Date: 2025-10-24
 * Dependencies: 026_create_tool_registry_table.sql
 */

-- Create status ENUM type
DO $$ BEGIN
  CREATE TYPE export_job_status AS ENUM (
    'pending',       -- Job created, not yet started
    'in_progress',   -- Job actively executing steps
    'completed',     -- Job finished successfully
    'failed',        -- Job failed with error
    'cancelled',     -- Job cancelled by user
    'cancelling',    -- Job cancellation in progress
    'rolled_back'    -- Job rolled back after failure
  );
EXCEPTION
  WHEN duplicate_object THEN null;
END $$;

-- Create export_jobs table
CREATE TABLE IF NOT EXISTS export_jobs (
  -- Primary Key
  job_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),

  -- Foreign Keys
  tool_id UUID NOT NULL REFERENCES tool_registry(tool_id) ON DELETE CASCADE,
  user_id UUID REFERENCES users(user_id) ON DELETE SET NULL,

  -- Job Status
  status export_job_status NOT NULL DEFAULT 'pending',

  -- Progress Tracking
  steps_completed INTEGER NOT NULL DEFAULT 0,
  steps_total INTEGER NOT NULL DEFAULT 0,
  current_step VARCHAR(255),
  progress_percentage INTEGER NOT NULL DEFAULT 0,

  -- Export Package Information
  package_path VARCHAR(500),
  package_size_bytes BIGINT,

  -- Error Information
  error_message TEXT,

  -- Audit Trail
  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
  started_at TIMESTAMP WITH TIME ZONE,
  completed_at TIMESTAMP WITH TIME ZONE,

  -- Constraints
  CONSTRAINT check_status_valid CHECK (status IN (
    'pending', 'in_progress', 'completed', 'failed',
    'cancelled', 'cancelling', 'rolled_back'
  )),
  CONSTRAINT check_steps_valid CHECK (steps_completed <= steps_total),
  CONSTRAINT check_progress_valid CHECK (progress_percentage BETWEEN 0 AND 100),
  CONSTRAINT check_package_size_valid CHECK (package_size_bytes IS NULL OR package_size_bytes >= 0)
);

-- Create Indexes for Query Performance
CREATE INDEX IF NOT EXISTS idx_export_jobs_tool_id ON export_jobs(tool_id);
CREATE INDEX IF NOT EXISTS idx_export_jobs_user_id ON export_jobs(user_id);
CREATE INDEX IF NOT EXISTS idx_export_jobs_status ON export_jobs(status);
CREATE INDEX IF NOT EXISTS idx_export_jobs_created_at ON export_jobs(created_at);
CREATE INDEX IF NOT EXISTS idx_export_jobs_user_created ON export_jobs(user_id, created_at DESC);

-- Add Comments
COMMENT ON TABLE export_jobs IS 'Tracks export job lifecycle and progress for tool exports';
COMMENT ON COLUMN export_jobs.job_id IS 'Unique export job identifier (UUID)';
COMMENT ON COLUMN export_jobs.tool_id IS 'Tool being exported (foreign key to tool_registry)';
COMMENT ON COLUMN export_jobs.user_id IS 'User who initiated export (nullable if user deleted)';
COMMENT ON COLUMN export_jobs.status IS 'Current job status (pending → in_progress → completed/failed)';
COMMENT ON COLUMN export_jobs.steps_completed IS 'Number of export steps completed';
COMMENT ON COLUMN export_jobs.steps_total IS 'Total number of export steps';
COMMENT ON COLUMN export_jobs.current_step IS 'Description of current export step';
COMMENT ON COLUMN export_jobs.progress_percentage IS 'Calculated progress percentage (0-100)';
COMMENT ON COLUMN export_jobs.package_path IS 'Filesystem path to generated export package (.tar.gz)';
COMMENT ON COLUMN export_jobs.package_size_bytes IS 'Size of export package in bytes';
COMMENT ON COLUMN export_jobs.error_message IS 'Error details if job failed';
```

**Why This Design:**

- **UUID Primary Key:** Globally unique identifiers, no conflicts across services
- **ENUM Status:** Enforces valid state transitions at database level
- **CHECK Constraints:** Data integrity enforced by database (steps_completed <= steps_total)
- **Timestamps:** Audit trail for job lifecycle (created, started, completed)
- **Indexes:** Optimized for common queries (user history, status filtering, polling)
- **Foreign Keys with Cascade:** Automatic cleanup when tools deleted, preserve jobs when users
  deleted

### Status State Machine

```
┌─────────┐
│ pending │
└────┬────┘
     │
     ↓
┌─────────────┐     ┌───────────┐
│ in_progress │ ──→ │ cancelling│
└──────┬──────┘     └─────┬─────┘
       │                  │
    ┌──┴──┐               │
    ↓     ↓               ↓
┌──────┐ ┌──────┐    ┌──────────┐
│completed│failed│    │cancelled │
└────────┘└───┬──┘    └──────────┘
              │
              ↓
        ┌────────────┐
        │rolled_back │
        └────────────┘
```

**State Transitions:**

1. **pending → in_progress:** Job starts executing steps
2. **in_progress → completed:** All steps finished successfully
3. **in_progress → failed:** Step execution error (triggers rollback)
4. **in_progress → cancelling:** User requests cancellation
5. **cancelling → cancelled:** Cancellation completed
6. **failed → rolled_back:** Rollback completed after failure

**Why State Machine:**

- Prevents invalid transitions (can't go from completed to pending)
- Enables tracking of cancellation in progress (cancelling state)
- Distinguishes between failed jobs and rolled-back jobs for debugging

### ExportJobRepository Implementation

```typescript
// apps/api/src/repositories/export-job.repository.ts
import { Pool, PoolClient } from 'pg';
import { ExportJob, ExportJobStatus } from '@nodeangularfullstack/shared';

/**
 * Repository for export_jobs table
 * Provides CRUD operations and query methods for export job tracking
 */
export class ExportJobRepository {
  constructor(private readonly pool: Pool) {}

  /**
   * Create new export job
   * @param jobData - Export job creation data
   * @returns Created export job record
   */
  async create(jobData: {
    jobId: string;
    toolId: string;
    userId: string;
    status: ExportJobStatus;
    stepsCompleted?: number;
    stepsTotal?: number;
    currentStep?: string;
  }): Promise<ExportJob> {
    const query = `
      INSERT INTO export_jobs (
        job_id, tool_id, user_id, status,
        steps_completed, steps_total, current_step
      )
      VALUES ($1, $2, $3, $4, $5, $6, $7)
      RETURNING *
    `;

    const values = [
      jobData.jobId,
      jobData.toolId,
      jobData.userId,
      jobData.status,
      jobData.stepsCompleted || 0,
      jobData.stepsTotal || 0,
      jobData.currentStep || null,
    ];

    const result = await this.pool.query(query, values);
    return this.mapRowToJob(result.rows[0]);
  }

  /**
   * Find export job by ID
   * @param jobId - Export job UUID
   * @returns Export job record or null if not found
   */
  async findById(jobId: string): Promise<ExportJob | null> {
    const query = 'SELECT * FROM export_jobs WHERE job_id = $1';
    const result = await this.pool.query(query, [jobId]);

    if (result.rows.length === 0) {
      return null;
    }

    return this.mapRowToJob(result.rows[0]);
  }

  /**
   * Update export job
   * @param jobId - Export job UUID
   * @param updates - Partial job data to update
   * @returns Updated export job record
   */
  async update(
    jobId: string,
    updates: Partial<{
      status: ExportJobStatus;
      stepsCompleted: number;
      stepsTotal: number;
      currentStep: string;
      progressPercentage: number;
      packagePath: string;
      packageSizeBytes: number;
      errorMessage: string;
      startedAt: Date;
      completedAt: Date;
    }>
  ): Promise<ExportJob> {
    const setClauses: string[] = ['updated_at = NOW()'];
    const values: any[] = [];
    let paramIndex = 1;

    // Build dynamic SET clause
    Object.entries(updates).forEach(([key, value]) => {
      if (value !== undefined) {
        const columnName = this.camelToSnake(key);
        setClauses.push(`${columnName} = $${paramIndex}`);
        values.push(value);
        paramIndex++;
      }
    });

    const query = `
      UPDATE export_jobs
      SET ${setClauses.join(', ')}
      WHERE job_id = $${paramIndex}
      RETURNING *
    `;

    values.push(jobId);

    const result = await this.pool.query(query, values);
    return this.mapRowToJob(result.rows[0]);
  }

  /**
   * Find export jobs by user ID
   * @param userId - User UUID
   * @param limit - Maximum number of jobs to return
   * @returns Array of export jobs sorted by created_at DESC
   */
  async findByUserId(userId: string, limit: number = 50): Promise<ExportJob[]> {
    const query = `
      SELECT * FROM export_jobs
      WHERE user_id = $1
      ORDER BY created_at DESC
      LIMIT $2
    `;

    const result = await this.pool.query(query, [userId, limit]);
    return result.rows.map((row) => this.mapRowToJob(row));
  }

  /**
   * Find export jobs by status
   * @param status - Export job status
   * @returns Array of export jobs with matching status
   */
  async findByStatus(status: ExportJobStatus): Promise<ExportJob[]> {
    const query = 'SELECT * FROM export_jobs WHERE status = $1 ORDER BY created_at ASC';
    const result = await this.pool.query(query, [status]);
    return result.rows.map((row) => this.mapRowToJob(row));
  }

  /**
   * Delete export jobs older than retention period
   * @param retentionDays - Number of days to retain jobs
   * @returns Number of deleted jobs
   */
  async deleteOldJobs(retentionDays: number): Promise<number> {
    const query = `
      DELETE FROM export_jobs
      WHERE created_at < NOW() - INTERVAL '${retentionDays} days'
      AND status IN ('completed', 'failed', 'cancelled', 'rolled_back')
      RETURNING job_id
    `;

    const result = await this.pool.query(query);
    return result.rowCount || 0;
  }

  /**
   * Map database row to ExportJob interface
   */
  private mapRowToJob(row: any): ExportJob {
    return {
      jobId: row.job_id,
      toolId: row.tool_id,
      userId: row.user_id,
      status: row.status as ExportJobStatus,
      stepsCompleted: row.steps_completed,
      stepsTotal: row.steps_total,
      currentStep: row.current_step,
      progressPercentage: row.progress_percentage,
      packagePath: row.package_path,
      packageSizeBytes: row.package_size_bytes ? parseInt(row.package_size_bytes, 10) : null,
      errorMessage: row.error_message,
      createdAt: row.created_at,
      updatedAt: row.updated_at,
      startedAt: row.started_at,
      completedAt: row.completed_at,
    };
  }

  /**
   * Convert camelCase to snake_case
   */
  private camelToSnake(str: string): string {
    return str.replace(/[A-Z]/g, (letter) => `_${letter.toLowerCase()}`);
  }
}
```

**Why This Implementation:**

- Repository pattern abstracts database access (testable with mocks)
- Dynamic UPDATE query supports partial updates (only update provided fields)
- `findByUserId()` includes pagination (LIMIT parameter)
- `deleteOldJobs()` for automated cleanup (cron job)
- `mapRowToJob()` converts snake_case columns to camelCase TypeScript properties

### Shared Types Definition

```typescript
// packages/shared/src/types/export.types.ts

/**
 * Export job status lifecycle states
 */
export enum ExportJobStatus {
  PENDING = 'pending',
  IN_PROGRESS = 'in_progress',
  COMPLETED = 'completed',
  FAILED = 'failed',
  CANCELLED = 'cancelled',
  CANCELLING = 'cancelling',
  ROLLED_BACK = 'rolled_back',
}

/**
 * Export job record
 */
export interface ExportJob {
  /** Unique export job identifier (UUID) */
  jobId: string;

  /** Tool being exported (foreign key to tool_registry) */
  toolId: string;

  /** User who initiated export (nullable if user deleted) */
  userId: string | null;

  /** Current job status */
  status: ExportJobStatus;

  /** Number of export steps completed */
  stepsCompleted: number;

  /** Total number of export steps */
  stepsTotal: number;

  /** Description of current export step */
  currentStep: string | null;

  /** Calculated progress percentage (0-100) */
  progressPercentage: number;

  /** Filesystem path to generated export package (.tar.gz) */
  packagePath: string | null;

  /** Size of export package in bytes */
  packageSizeBytes: number | null;

  /** Error details if job failed */
  errorMessage: string | null;

  /** Job creation timestamp */
  createdAt: Date;

  /** Last update timestamp */
  updatedAt: Date;

  /** Job start timestamp */
  startedAt: Date | null;

  /** Job completion timestamp */
  completedAt: Date | null;
}

/**
 * Export job creation DTO
 */
export interface CreateExportJobDto {
  jobId: string;
  toolId: string;
  userId: string;
  status?: ExportJobStatus;
  stepsCompleted?: number;
  stepsTotal?: number;
  currentStep?: string;
}

/**
 * Export job update DTO
 */
export interface UpdateExportJobDto {
  status?: ExportJobStatus;
  stepsCompleted?: number;
  stepsTotal?: number;
  currentStep?: string;
  progressPercentage?: number;
  packagePath?: string;
  packageSizeBytes?: number;
  errorMessage?: string;
  startedAt?: Date;
  completedAt?: Date;
}
```

**Why TypeScript Interfaces:**

- Shared between frontend and backend (type safety)
- Enum for status ensures valid values at compile time
- DTOs simplify API contracts (create vs update payloads)

### Query Performance Analysis

```sql
-- Query 1: Find export job by ID (most frequent - polling)
EXPLAIN ANALYZE
SELECT * FROM export_jobs WHERE job_id = 'abc-123';

-- Expected: Index Scan using export_jobs_pkey (< 1ms)
-- PRIMARY KEY index ensures O(log n) lookup

-- Query 2: Find user's export history (sorted)
EXPLAIN ANALYZE
SELECT * FROM export_jobs
WHERE user_id = 'user-456'
ORDER BY created_at DESC
LIMIT 50;

-- Expected: Index Scan using idx_export_jobs_user_created (< 50ms)
-- Composite index (user_id, created_at DESC) enables index-only scan

-- Query 3: Find pending jobs for job queue
EXPLAIN ANALYZE
SELECT * FROM export_jobs
WHERE status = 'pending'
ORDER BY created_at ASC;

-- Expected: Index Scan using idx_export_jobs_status (< 100ms)
-- Status index filters efficiently, sort by created_at

-- Query 4: Cleanup old jobs
EXPLAIN ANALYZE
DELETE FROM export_jobs
WHERE created_at < NOW() - INTERVAL '30 days'
AND status IN ('completed', 'failed', 'cancelled');

-- Expected: Index Scan using idx_export_jobs_created_at (< 500ms)
-- Created_at index enables efficient date range queries
```

**Why Indexing Strategy:**

- **PRIMARY KEY (job_id):** O(log n) lookups for polling (most frequent query)
- **Composite (user_id, created_at DESC):** Enables sorted user history without separate sort
  operation
- **status INDEX:** Filters pending/in_progress jobs efficiently
- **created_at INDEX:** Cleanup queries for old jobs

---

## Testing

### Migration Test Example

```bash
# Test UP migration
npm --workspace=apps/api run db:migrate

# Verify table exists
psql -U postgres -d nodeangularfullstack -c "\d export_jobs"

# Test idempotency (run again)
npm --workspace=apps/api run db:migrate

# Test DOWN migration
psql -U postgres -d nodeangularfullstack -f apps/api/database/migrations/DOWN_027_drop_export_jobs_table.sql

# Verify table dropped
psql -U postgres -d nodeangularfullstack -c "\d export_jobs"
```

### Integration Test Example

```typescript
// apps/api/tests/integration/export-job.repository.integration.test.ts
import { ExportJobRepository } from '../../../src/repositories/export-job.repository';
import { ExportJobStatus } from '@nodeangularfullstack/shared';
import { Pool } from 'pg';

describe('ExportJobRepository Integration Tests', () => {
  let repository: ExportJobRepository;
  let pool: Pool;

  beforeAll(async () => {
    pool = new Pool({
      host: 'localhost',
      port: 5432,
      database: 'nodeangularfullstack_test',
      user: 'postgres',
      password: 'dbpassword',
    });

    repository = new ExportJobRepository(pool);

    // Run migrations
    // await runMigrations(pool);
  });

  afterAll(async () => {
    await pool.end();
  });

  describe('create', () => {
    it('should insert new export job', async () => {
      const jobData = {
        jobId: 'test-job-123',
        toolId: 'tool-forms-456', // Assumes tool exists from seed
        userId: 'admin-user-789', // Assumes user exists from seed
        status: ExportJobStatus.PENDING,
        stepsCompleted: 0,
        stepsTotal: 8,
        currentStep: 'Initializing...',
      };

      const job = await repository.create(jobData);

      expect(job.jobId).toBe('test-job-123');
      expect(job.toolId).toBe('tool-forms-456');
      expect(job.status).toBe(ExportJobStatus.PENDING);
      expect(job.createdAt).toBeInstanceOf(Date);
    });

    it('should fail with invalid tool_id (foreign key constraint)', async () => {
      const jobData = {
        jobId: 'test-job-456',
        toolId: 'invalid-tool-id',
        userId: 'admin-user-789',
        status: ExportJobStatus.PENDING,
      };

      await expect(repository.create(jobData)).rejects.toThrow();
    });
  });

  describe('findById', () => {
    it('should retrieve export job by ID', async () => {
      // Create job first
      const jobData = {
        jobId: 'test-job-789',
        toolId: 'tool-forms-456',
        userId: 'admin-user-789',
        status: ExportJobStatus.PENDING,
      };

      await repository.create(jobData);

      // Retrieve job
      const job = await repository.findById('test-job-789');

      expect(job).not.toBeNull();
      expect(job?.jobId).toBe('test-job-789');
    });

    it('should return null for non-existent job', async () => {
      const job = await repository.findById('non-existent-job');
      expect(job).toBeNull();
    });
  });

  describe('update', () => {
    it('should update job status and progress', async () => {
      // Create job
      const jobData = {
        jobId: 'test-job-update',
        toolId: 'tool-forms-456',
        userId: 'admin-user-789',
        status: ExportJobStatus.PENDING,
        stepsCompleted: 0,
        stepsTotal: 8,
      };

      await repository.create(jobData);

      // Update job
      const updatedJob = await repository.update('test-job-update', {
        status: ExportJobStatus.IN_PROGRESS,
        stepsCompleted: 3,
        progressPercentage: 37,
        currentStep: 'Generating boilerplate...',
      });

      expect(updatedJob.status).toBe(ExportJobStatus.IN_PROGRESS);
      expect(updatedJob.stepsCompleted).toBe(3);
      expect(updatedJob.progressPercentage).toBe(37);
    });
  });
});
```

---

## Dependencies

### Blocked By:

- Story 30.1.1: Tool Registry Database Schema (tool_id foreign key)
- Backend users table exists (user_id foreign key)

### Blocks:

- Story 33.1.1: Export Orchestrator Service (requires ExportJobRepository)
- Story 33.1.3: Export Job Status Tracking (requires export_jobs table)

### Related:

- Story 32.2.4: Export Progress Modal (consumes job status via API)

---

## QA Gate

**Gate File:** `docs/qa/gates/33.1.2-export-jobs-database-schema.yml`

### Quality Criteria (Weighted):

| Criterion           | Weight | Target                     | Validation Method |
| ------------------- | ------ | -------------------------- | ----------------- |
| Migration Success   | 25%    | UP/DOWN migrations work    | Manual testing    |
| Schema Constraints  | 20%    | All constraints enforced   | Integration tests |
| Repository Coverage | 20%    | ≥90% test coverage         | Jest coverage     |
| Query Performance   | 15%    | Queries < 100ms (10K rows) | Performance tests |
| Documentation       | 10%    | Schema documented          | Code review       |
| Index Effectiveness | 10%    | Indexes used by queries    | EXPLAIN ANALYZE   |

**Minimum Score:** 90/100 to pass gate

---

## Notes

### ★ Insight ─────────────────────────────────────

**Database Design Principles:**

- **Normalization:** export_jobs table normalized (no redundant data)
- **Referential Integrity:** Foreign keys enforce relationships at database level
- **Data Integrity:** CHECK constraints enforce business rules (progress 0-100)

**Indexing Strategy:**

- **Selective Indexes:** Index columns used in WHERE clauses (status, user_id, created_at)
- **Composite Indexes:** Cover common multi-column queries (user_id + created_at)
- **Trade-offs:** Indexes speed reads but slow writes (acceptable for export_jobs -
  write-infrequent)

**Why Repository Pattern:**

- **Abstraction:** Hides SQL details from business logic
- **Testability:** Mock repository in service tests (no database dependency)
- **Consistency:** Centralized query logic prevents SQL duplication

─────────────────────────────────────────────────

**Story State:** Draft **Last Updated:** 2025-10-24 **Next Review:** After implementation completion
